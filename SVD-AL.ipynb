{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee55cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from surprise import BaselineOnly\n",
    "# from surprise import NMF\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import AlgoBase\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "# import sys\n",
    "import math\n",
    "import statistics\n",
    "import collections\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "my_seed = 0\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import timeit\n",
    "\n",
    "# from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f20f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.13\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897fa6eb",
   "metadata": {},
   "source": [
    "# Rating Data Overwrite for 'userfixed' data split feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b848417",
   "metadata": {},
   "source": [
    "Splitting the data using the userfixed method, where 80% of each user's data goes to training and the rest to testing set. Surprises split method is randomly. Their method is extended below.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590b89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset:\n",
    "    import numpy as np\n",
    "    from scipy import sparse\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rating_mat = None\n",
    "        # self.time_mat = None\n",
    "        self._data_file_path = ''\n",
    "        \n",
    "        # list of raw user_IDs (dataset IDs)\n",
    "        self.items = []\n",
    "        self.users = []\n",
    "        self.item_n = 0\n",
    "        self.user_n = 0\n",
    "        \n",
    "        # maps raw user_id to user_iid(or inner id)\n",
    "        self.user_to_iid = {}\n",
    "        # maps user inner id to dataset raw ID\n",
    "        self.user_to_ID = {}\n",
    "        # maps raw item_id (dataset) to item_iid(or inner id)\n",
    "        self.item_to_iid = {}\n",
    "        # maps item inner id to dataset raw ID\n",
    "        self.item_to_ID = {}\n",
    "        \n",
    "        # list of triples of (item, rating, timestamp) for each user_iid. \n",
    "        # TODO: In case there were no Timestamp in the data, pairs of (item, rating) will be kept\n",
    "        self.user_ratings = []\n",
    "        # list of pair of (user, rating) for each item_iid\n",
    "        self.item_ratings = []\n",
    "        \n",
    "        \n",
    "    def __get_line_format_indices(self, line_format):\n",
    "        # specifying the order of 'user, item, rating, timestamp' in each line \n",
    "        lf_sp = line_format.split(' ')\n",
    "        # if len(lf_sp) != 4:\n",
    "        #     raise Exception('''Bad line format!\n",
    "        #     line_format should be space-separated and it should always specified by \n",
    "        #     \"user item rating timestamp\" with any order!''')\n",
    "        user_idx = -1\n",
    "        item_idx = -1\n",
    "        rating_idx = -1\n",
    "        # timestamp_idx = -1\n",
    "        for c in range(len(lf_sp)):\n",
    "            if lf_sp[c] == 'user':\n",
    "                user_idx = c\n",
    "            elif lf_sp[c] == 'item':\n",
    "                item_idx = c\n",
    "            elif lf_sp[c] == 'rating':\n",
    "                rating_idx = c\n",
    "            # elif lf_sp[c] == 'timestamp':\n",
    "            #     timestamp_idx = c\n",
    "            else:\n",
    "                raise Exception('line_format must be exactly dictated by one of: (user/item/rating/timestamp) separated by sep!')\n",
    "        \n",
    "        # return user_idx, item_idx, rating_idx, timestamp_idx\n",
    "        return user_idx, item_idx, rating_idx\n",
    "    \n",
    "    \n",
    "    '''\n",
    "        Read the rating data from file and parse it and then make the dataset.\n",
    "    '''\n",
    "    # def read_from_file(self, data_fn, skip_lines=0, sep=',', line_format='user item rating timestamp'):\n",
    "    def read_from_file(self, data_fn, skip_lines=0, sep=',', line_format='user item rating'):\n",
    "        \n",
    "        # user_fmt_idx, item_fmt_idx, rating_fmt_idx, timestamp_fmt_idx = self.__get_line_format_indices(line_format)\n",
    "        user_fmt_idx, item_fmt_idx, rating_fmt_idx = self.__get_line_format_indices(line_format)\n",
    "        \n",
    "        file = open(data_fn, 'r')\n",
    "        \n",
    "        # skip lines that are specified from input\n",
    "        for _ in range(skip_lines):\n",
    "            file.readline()\n",
    "            \n",
    "        # users list as in input file\n",
    "        users_lin = []\n",
    "        items_lin = []\n",
    "        ratings_lin = []\n",
    "        # timestamps_lin = []\n",
    "        for l in file:\n",
    "            lsp = l.split(sep)\n",
    "            user_id = lsp[user_fmt_idx]\n",
    "            item_id = lsp[item_fmt_idx]\n",
    "            rating = float(lsp[rating_fmt_idx])\n",
    "            # timestamp = int(lsp[timestamp_fmt_idx].strip('\\n'))\n",
    "            \n",
    "            users_lin.append(user_id)\n",
    "            items_lin.append(item_id)\n",
    "            ratings_lin.append(rating)\n",
    "            # timestamps_lin.append(timestamp)\n",
    "            \n",
    "        self.users = list(set(users_lin))\n",
    "        self.items = list(set(items_lin))\n",
    "        \n",
    "        self.user_n = len(self.users)\n",
    "        self.item_n = len(self.items)\n",
    "        \n",
    "        '''note that raw ids are in STRING format, and the iid in INTEGER format!'''\n",
    "        # set the mappings\n",
    "        for idx in range(self.user_n): \n",
    "            self.user_to_iid[self.users[idx]] = idx\n",
    "            \n",
    "        for idx in range(self.user_n):\n",
    "            self.user_to_ID[idx] = self.users[idx] \n",
    "            \n",
    "        for idx in range(self.item_n):\n",
    "            self.item_to_iid[self.items[idx]] = idx \n",
    "            \n",
    "        for idx in range(self.item_n):\n",
    "            self.item_to_ID[idx] = self.items[idx] \n",
    "        \n",
    "        # init rating matrix\n",
    "        self.rating_mat = sparse.lil_matrix((self.user_n, self.item_n))\n",
    "        # self.time_mat = sparse.lil_matrix((self.user_n, self.item_n))\n",
    "        for idx in range(len(users_lin)):\n",
    "            user_iid = self.user_to_iid[users_lin[idx]]\n",
    "            item_iid = self.item_to_iid[items_lin[idx]]\n",
    "            rating = ratings_lin[idx]\n",
    "            self.rating_mat[user_iid, item_iid] = rating\n",
    "            # self.time_mat[user_iid, item_iid] = timestamps_lin[idx]\n",
    "            \n",
    "            \n",
    "    def list_users_ratings(self, rating_matrix):\n",
    "        # finding the user and item ratings\n",
    "        user_ratings = []\n",
    "        for user_iid in range(self.user_n):\n",
    "            # append a list for this user\n",
    "            user_ratings.append([])\n",
    "            user_nonze = np.nonzero(rating_matrix[user_iid])\n",
    "            for item_iid in user_nonze[1]:\n",
    "                # add items and its rating into the last user added to the list\n",
    "                user_ratings[-1].append((item_iid, rating_matrix[user_iid, item_iid]))\n",
    "                if rating_matrix[user_iid, item_iid] == 0:\n",
    "                    raise Exception('Found zero rating in nonzero ratings of user with inner id %d and item iid %d!' % (user_iid, item_iid))\n",
    "        return user_ratings\n",
    "    \n",
    "            \n",
    "    def list_items_ratings(self, rating_matrix):\n",
    "        item_ratings = []\n",
    "        for item_iid in range(self.item_n):\n",
    "            # append a list for this item\n",
    "            item_ratings.append([])\n",
    "            item_nonze = np.nonzero(rating_matrix.T[item_iid])\n",
    "            for user_iid in item_nonze[1]:\n",
    "                # add users and its rating into the last item added to the list\n",
    "                item_ratings[-1].append((user_iid, rating_matrix[user_iid, item_iid]))\n",
    "                if rating_matrix[user_iid, item_iid] == 0:\n",
    "                    raise Exception('Found zero rating in nonzero ratings of user with inner id %d and item iid %d!' % (user_iid, item_iid))\n",
    "        return item_ratings\n",
    "        \n",
    "            \n",
    "    def train_test_split(self, test_percent=0.2, least_userlen_test=10):\n",
    "        if test_percent > 1:\n",
    "            raise Exception('test_percent should be between 0 and 1.')\n",
    "            \n",
    "        user_ratings = self.list_users_ratings(self.rating_mat)\n",
    "        \n",
    "        mat = sparse.lil_matrix((self.user_n, self.item_n))\n",
    "        user_tests = {}\n",
    "        n_users_in_test = 0\n",
    "        n_ratings_in_test = 0\n",
    "        n_ratings_in_train = 0\n",
    "        \n",
    "        for user_iid in range(self.user_n):\n",
    "            len_u = len(user_ratings[user_iid])\n",
    "            if len_u >= least_userlen_test:\n",
    "                n_users_in_test += 1\n",
    "                test_len = int(len_u * test_percent)\n",
    "                test_set_u = list(range(len_u))\n",
    "#                 print(test_len, len_u)\n",
    "                random.shuffle(test_set_u)\n",
    "                \n",
    "                train_set_u = test_set_u[test_len:][:]\n",
    "                test_set_u = test_set_u[:test_len][:]\n",
    "                \n",
    "#                 print(len(train_set_u))\n",
    "                \n",
    "                for ir_idx in train_set_u:\n",
    "                    # ir = the pair of (item, rating)\n",
    "                    ir = user_ratings[user_iid][ir_idx]\n",
    "                    mat[user_iid, ir[0]] = ir[1]\n",
    "                    n_ratings_in_train += 1\n",
    "                \n",
    "                user_tests[user_iid] = []\n",
    "                for ir_idx in test_set_u:\n",
    "                    # ir = the pair of (item, rating)\n",
    "                    ir = user_ratings[user_iid][ir_idx]\n",
    "                    user_tests[user_iid].append(ir)\n",
    "                    n_ratings_in_test += 1\n",
    "                    \n",
    "            else: # if no test set should be seprated from ratings of this user\n",
    "                for ir in user_ratings[user_iid]:\n",
    "                    # ir = the pair of (item, rating)\n",
    "                    mat[user_iid, ir[0]] = ir[1]\n",
    "                    n_ratings_in_train += 1\n",
    "    \n",
    "        print('\\nNumber of users with some items in testset: %d' % n_users_in_test)\n",
    "        print('Number of ratings in trainset: %d \\t Number of ratings in testset: %d\\n' % (n_ratings_in_train, n_ratings_in_test))\n",
    "        return mat, user_tests\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be0f7a",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ee879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ml-100k/udata.csv', \n",
    "                 sep=\";\", header=0, engine=\"python\")\n",
    "\n",
    "user = pd.read_csv('ml-100k/uuser.csv', \n",
    "                   sep=\";\", header=0, engine =\"python\")\n",
    "\n",
    "genre = pd.read_csv('ml-100k/ugenre.csv', \n",
    "                    sep=\";\", header=0, engine = \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b6a0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  age gender  occupation zipcode\n",
       "0   1   24      M  technician   85711\n",
       "1   2   53      F       other   94043\n",
       "2   3   23      M      writer   32067\n",
       "3   4   24      M  technician   43537\n",
       "4   5   33      F       other   15213"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8ac59",
   "metadata": {},
   "source": [
    "# dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6365bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_core = 45  # minimal number of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bea431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_items = df['item'].value_counts() > 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d967a89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original data frame shape:\t(100000, 3)\n",
      "The new data frame shape:\t(76420, 3)\n",
      "\n",
      "The original data frame shape:\t(76420, 3)\n",
      "The new data frame shape:\t(73656, 3)\n",
      "\n",
      "The original data frame shape:\t(73656, 3)\n",
      "The new data frame shape:\t(73003, 3)\n",
      "\n",
      "The original data frame shape:\t(73003, 3)\n",
      "The new data frame shape:\t(72690, 3)\n",
      "\n",
      "The original data frame shape:\t(72690, 3)\n",
      "The new data frame shape:\t(72600, 3)\n",
      "\n",
      "The original data frame shape:\t(72600, 3)\n",
      "The new data frame shape:\t(72600, 3)\n",
      "\n",
      "(72600, 3)\n",
      "   user  item  rating\n",
      "1   186   302       3\n",
      "3   244    51       2\n",
      "5   298   474       4\n",
      "6   115   265       2\n",
      "7   253   465       5\n",
      "\n",
      "#users:  (551,)\n",
      "#items:  (593,)\n"
     ]
    }
   ],
   "source": [
    "# To reduce the dimensionality of the dataset,\n",
    "# we will filter out rarely rated movies and rarely rating users\n",
    "\n",
    "min_ratings = n_core\n",
    "min_user_ratings = n_core\n",
    "\n",
    "init_df = df\n",
    "init_shp = df.shape[0]\n",
    "filt_shp = 0.0\n",
    "\n",
    "while True:\n",
    "\n",
    "    filter_items = init_df['item'].value_counts() > min_ratings\n",
    "    filter_items = filter_items[filter_items == True].index.tolist()\n",
    "\n",
    "    filter_users = init_df['user'].value_counts() > min_user_ratings\n",
    "    filter_users = filter_users[filter_users == True].index.tolist()\n",
    "\n",
    "    filt_df = init_df[(init_df['item'].isin(filter_items)) & (init_df['user'].isin(filter_users))]\n",
    "\n",
    "    print('The original data frame shape:\\t{}'.format(init_df.shape))\n",
    "    print('The new data frame shape:\\t{}'.format(filt_df.shape))\n",
    "    print()\n",
    "    \n",
    "    init_shp = init_df.shape[0]\n",
    "    filt_shp = filt_df.shape[0]\n",
    "    \n",
    "    # print(init_shp, filt_shp)\n",
    "    \n",
    "    if (init_shp == filt_shp):\n",
    "        break\n",
    "    \n",
    "    init_df = filt_df\n",
    "\n",
    "    \n",
    "#------------------------------------------------------------\n",
    "'Updating the df to its filtered version'\n",
    "'Now filt-df is called df.' \n",
    "df = filt_df\n",
    "print(filt_df.shape)\n",
    "print(df.head())\n",
    "\n",
    "print()\n",
    "print('#users: ', np.unique(df['user']).shape)\n",
    "print('#items: ', np.unique(df['item']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eb22cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./filtered_ml_%icore.csv'%n_core, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26994c",
   "metadata": {},
   "source": [
    "# Split into test and train with the 'userfixed' method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8135d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users 551\n",
      "# items 593\n",
      "\n",
      "Number of users with some items in testset: 551\n",
      "Number of ratings in trainset: 58307 \t Number of ratings in testset: 14293\n",
      "\n",
      "(551, 593)\n"
     ]
    }
   ],
   "source": [
    "# data = Dataset.load_from_df(df[['user', 'item', 'rating']], reader)\n",
    "\n",
    "dataset = RatingDataset()\n",
    "data_fn = './filtered_ml_%icore.csv'%n_core\n",
    "dataset.read_from_file(data_fn, skip_lines=1, line_format='user item rating', sep=',')\n",
    "\n",
    "\n",
    "print('# users', dataset.user_n)\n",
    "print('# items', dataset.item_n)\n",
    "\n",
    "\n",
    "# user_tests is the test_mat\n",
    "train_mat, test_mat = dataset.train_test_split(test_percent=0.2, least_userlen_test=10)\n",
    "\n",
    "\n",
    "# ir = the pair of (item, rating)\n",
    "# ir = user_ratings[user_iid][ir_idx]\n",
    "user_ratings = dataset.list_users_ratings(dataset.rating_mat)\n",
    "print(dataset.rating_mat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb5122a",
   "metadata": {},
   "source": [
    "# convert train and test into dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5734fa",
   "metadata": {},
   "source": [
    "## train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d78c88c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0     7     3.0\n",
       "1     0    16     5.0\n",
       "2     0    26     3.0\n",
       "3     0    27     4.0\n",
       "4     0    29     3.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings = dataset.list_users_ratings(train_mat)\n",
    "# user_ratings[0]\n",
    "# train_df = pd.DataFrame(columns = ['item','rating'])\n",
    "\n",
    "\n",
    "tr_lst = []\n",
    "\n",
    "for user_iid in range(dataset.user_n): \n",
    "    # trainset or dataset.user_n?? we keep the users the same (user-fixed) so they are equal.\n",
    "    \n",
    "    if user_ratings[user_iid]:\n",
    "        base_rec = pd.DataFrame(user_ratings[user_iid])\n",
    "        base_rec[2] = user_iid\n",
    "\n",
    "        tr_lst.append(base_rec[[2,0,1]])\n",
    "    \n",
    "\n",
    "train_df = pd.concat(tr_lst, ignore_index=True)\n",
    "train_df.columns = ['user','item','rating']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b16df2",
   "metadata": {},
   "source": [
    "## test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abed1861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>574</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>462</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0   508     4.0\n",
       "1     0   168     4.0\n",
       "2     0   550     2.0\n",
       "3     0   574     3.0\n",
       "4     0   462     5.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test set to a dataframe\n",
    "test_lst = []\n",
    "\n",
    "for uiid in test_mat.keys():\n",
    "    base_rec = pd.DataFrame(test_mat[uiid])\n",
    "    base_rec[2] = uiid\n",
    "    test_lst.append(base_rec[[2,0,1]])\n",
    "\n",
    "\n",
    "test_df = pd.concat(test_lst, ignore_index=True)\n",
    "test_df.columns = ['user','item','rating']\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c5a1a7",
   "metadata": {},
   "source": [
    "# SVD, and how to prepare data into a format readbale for Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811ca7ad",
   "metadata": {},
   "source": [
    "if you want to add back items, you can add them back to the dataframe and build th train again as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4179eb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9062879314040293\n",
      "\n",
      " in ms : \n",
      "\n",
      "0:00:00.745999\n"
     ]
    }
   ],
   "source": [
    "tstart = datetime.now()\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "oracle_SVD = SVD()\n",
    "\n",
    "rmse_lst = []\n",
    "\n",
    "# build the train into surprise format\n",
    "trainset_all = Dataset.load_from_df(train_df[['user', 'item', 'rating']], reader).build_full_trainset()\n",
    "\n",
    "# build test set into surpirse format\n",
    "testset_all = Dataset.load_from_df(test_df[['user', 'item', 'rating']], reader).build_full_trainset().build_testset()\n",
    "\n",
    "# fit \n",
    "oracle_SVD.fit(trainset_all)\n",
    "\n",
    "# predictions\n",
    "fin_preds = oracle_SVD.test(testset_all)\n",
    "\n",
    "# get the RMSE\n",
    "fin_acc = accuracy.rmse(fin_preds, verbose=False)\n",
    "\n",
    "# print\n",
    "print(fin_acc)\n",
    "\n",
    "tend = datetime.now()    \n",
    "print(\"\\n in ms : \\n\")\n",
    "print(tend-tstart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4096af1",
   "metadata": {},
   "source": [
    "# Accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "522a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# ground_truth: list of items ordered by time\n",
    "def nDCG_Time(ground_truth, _recList):\n",
    "    rec_num = len(_recList) # topK\n",
    "    # ground_truth is already sorted by time\n",
    "    idealOrder = ground_truth\n",
    "    idealDCG = 0.0\n",
    "    for j in range(min(rec_num, len(idealOrder))):\n",
    "        idealDCG += ((math.pow(2.0, len(idealOrder) - j) - 1) / math.log(2.0 + j))\n",
    "\n",
    "    recDCG = 0.0\n",
    "    for j in range(rec_num):\n",
    "        item = _recList[j]\n",
    "        if item in ground_truth:\n",
    "            rank = len(ground_truth) - ground_truth.index(item) # why ground truth?\n",
    "            recDCG += ((math.pow(2.0, rank) - 1) / math.log(1.0 + j + 1))\n",
    "\n",
    "    return (recDCG / idealDCG)\n",
    "\n",
    "\n",
    "def Recall(_test_set, _recList):\n",
    "    hit = len(set(_recList).intersection(set(_test_set)))\n",
    "    return hit / float(len(_test_set))\n",
    "\n",
    "\n",
    "def Precision(_test_set, _recList):\n",
    "    hit = len(set(_recList).intersection(set(_test_set)))\n",
    "    return hit / float(len(_recList))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d486c",
   "metadata": {},
   "source": [
    "# Non-negtive Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59752f3e",
   "metadata": {},
   "source": [
    "## choose the topk function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cb5bfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recNMF_2(user_iid, _est, mat, topk):\n",
    "    \n",
    "    rated_before = np.nonzero(mat[user_iid, :])[1]\n",
    "    estimations = _est[user_iid]\n",
    "    estimations[rated_before] = 0 \n",
    "    # you don't want to recommend the items to the user that have rated before duh!\n",
    "    \n",
    "    # top_items = np.argpartition(-estimations, topk)[:topk]\n",
    "    top_items = np.argsort(-estimations)[:topk]\n",
    "    top_ratings = -np.sort(-estimations)[:topk]\n",
    "    \n",
    "    return (user_iid, top_items, top_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b21fd9",
   "metadata": {},
   "source": [
    "## making the predictions by multiplying the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21f5b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programs\\Anaconda3\\envs\\active-learning\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1477: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time: 0.18 secs\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "from sklearn.decomposition import NMF\n",
    "feature_n = 40\n",
    "\n",
    "mf = NMF(n_components=feature_n, init='random', random_state=2, tol=0.01,\n",
    "         solver='cd', max_iter=1000, alpha=1, beta_loss='frobenius',\n",
    "         l1_ratio=0)\n",
    "\n",
    "\n",
    "user_f = mf.fit_transform(train_mat)\n",
    "H = mf.components_\n",
    "item_f = mf.components_.T\n",
    "\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Process Time: %.2f secs' % (stop - start))\n",
    "start = timeit.default_timer()\n",
    "est = np.dot(user_f, item_f.T)\n",
    "res = []\n",
    "\n",
    "# Choose it to be 1000 instead of 10, and then the re-ranker will chose the final top 10\n",
    "for u in range(dataset.user_n):\n",
    "    res.append(recNMF_2(u, est, train_mat, 200))\n",
    "    \n",
    "user_recs_allinclude = {}\n",
    "for x in res:\n",
    "    user_recs_allinclude[x[0]] = x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae697ed",
   "metadata": {},
   "source": [
    "## saving the base recommendaitons: give it a new path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b521cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_rec_list = []\n",
    "for i in range(len(res)):\n",
    "    base_rec = pd.DataFrame(res[i][1:]).T\n",
    "    base_rec[2] = res[i][0]\n",
    "    u_rec_list.append(base_rec[[2,0,1]])\n",
    "\n",
    "u_rec_df = pd.concat(u_rec_list, ignore_index=True)\n",
    "\n",
    "# u_rec_df.to_csv('./ml_results/nmf_base_rec_ML_.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51b937",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28de5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time: 3.88 secs\n",
      " avg-precision 0.317\n",
      " avg-recall 0.239\n",
      " avg-nDCG 0.163\n"
     ]
    }
   ],
   "source": [
    "stop = timeit.default_timer()\n",
    "print('Process Time: %.2f secs' % (stop - start))\n",
    "\n",
    "p = []\n",
    "r = []\n",
    "n = []\n",
    "\n",
    "for u in test_mat.keys():\n",
    "    if len(test_mat[u]) > 0:\n",
    "        \n",
    "        test_items = [t[0] for t in test_mat[u] if t[1] >= 4]\n",
    "        \n",
    "        if len(test_items) > 0:\n",
    "            # to be comparable with the other algorithms, the list size should be the same that is 10 here.\n",
    "            top_items = user_recs_allinclude[u][:10] \n",
    "            \n",
    "            recall = Recall(test_items, top_items)\n",
    "            precision = Precision(test_items, top_items)\n",
    "            ndcg = nDCG_Time(test_items, top_items)\n",
    "\n",
    "            p.append(precision)\n",
    "            r.append(recall)\n",
    "            n.append(ndcg)\n",
    "\n",
    "print (\" avg-precision %.3f\\n avg-recall %.3f\\n avg-nDCG %.3f\" %\n",
    "       (np.average(p),np.average(r),np.average(n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c84ec",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42da00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionBasedActiveLearner:\n",
    "\n",
    "    def __init__(self, decomposer, strategy, initial_train_df=None):\n",
    "        '''\n",
    "        Prediction-based active learner class.\n",
    "\n",
    "        Args:\n",
    "            decomoser:        sklearn.decomposition, decomposition algorithm to be used \n",
    "                                                     to decompose rating matrix.\n",
    "            strategy:         str, active learning strategy, \n",
    "                                   one of ('MaxRating', 'MinRating', 'MixRating').\n",
    "            initial_train_df: DataFrame, initial training DataFrame.\n",
    "        '''\n",
    "\n",
    "        self.decomposer = decomposer\n",
    "        self.strategy = strategy\n",
    "        self.user_f = None\n",
    "        self.item_f = None \n",
    "        self.est = None\n",
    "\n",
    "        # remember unavailable queries (kind of cheating?)\n",
    "        self.unavl = {i: [] for i in range(dataset.user_n)}\n",
    "\n",
    "        if initial_train_df is not None:\n",
    "            self.known_mat = self._convert_df_to_mat(initial_train_df)\n",
    "\n",
    "            self.user_f = self.decomposer.fit_transform(self.known_mat)\n",
    "            self.item_f = self.decomposer.components_.T\n",
    "            self.est = np.dot(self.user_f, self.item_f.T)\n",
    "\n",
    "        else:\n",
    "            self.known_mat = sparse.lil_matrix((dataset.user_n, dataset.item_n))\n",
    "\n",
    "    def _convert_df_to_mat(self, df):\n",
    "        '''\n",
    "        Convert DaraFrame to sparse matrix\n",
    "        \n",
    "        Arg:\n",
    "            df: DataFrame, training DataFrame\n",
    "        \n",
    "        Return:\n",
    "            mat: lil_matrix, sparse matrix containing training data\n",
    "        '''\n",
    "\n",
    "        mat = sparse.lil_matrix((dataset.user_n, dataset.item_n))\n",
    "        for _, row in df.iterrows():\n",
    "            user_iid = int(row[0])\n",
    "            item_iid = int(row[1])\n",
    "            rating = row[2]\n",
    "            mat[user_iid, item_iid] = rating\n",
    "        \n",
    "        return mat \n",
    "\n",
    "    def add_query(self, query_df):\n",
    "        '''\n",
    "        Add queried data to known matrix.\n",
    "        \n",
    "        Arg:\n",
    "            query_df: DataFrame, new data to be added.\n",
    "        '''\n",
    "\n",
    "        for _, row in query_df.iterrows():\n",
    "            user_iid = int(row[0])\n",
    "            item_iid = int(row[1])\n",
    "            rating = row[2]\n",
    "            self.known_mat[user_iid, item_iid] = rating\n",
    "\n",
    "    def train(self):\n",
    "        '''\n",
    "        Fit self.decomposer to known data.\n",
    "        '''\n",
    "\n",
    "        self.user_f = self.decomposer.fit_transform(self.known_mat)\n",
    "        self.item_f = self.decomposer.components_.T\n",
    "\n",
    "        self.est = np.dot(self.user_f, self.item_f.T)\n",
    "\n",
    "        # return self to enable learner.train().predict()\n",
    "        # return self\n",
    "    \n",
    "    def predict(self, user_iid, item_iid):\n",
    "        '''\n",
    "        Estimate rating of user and item pair.\n",
    "\n",
    "        Args:\n",
    "            user_iid: int, inner id of the user to be predicted\n",
    "            item_iid: int, inner id of the item to be predicted\n",
    "        \n",
    "        Return:\n",
    "            float\n",
    "        '''\n",
    "\n",
    "        return self.est[user_iid, item_iid]\n",
    "    \n",
    "    def query(self, user_iid, topk):\n",
    "        '''\n",
    "        Find the indices of candidates which should be queried for true ratings.\n",
    "\n",
    "        Args:\n",
    "            user_iid: int, inner id of the user to be queried\n",
    "            topk:     int, number of queried candidates\n",
    "        \n",
    "        Return:\n",
    "            (top_items, top_ratings): (numpy int array, numpy float array)\n",
    "        '''\n",
    "        \n",
    "        rated_before = np.nonzero(self.known_mat[user_iid, :])[1]\n",
    "        unavailable = self.unavl[user_iid]\n",
    "        \n",
    "        estimations = self.est[user_iid]\n",
    "        estimations[rated_before] = 0\n",
    "        estimations[unavailable] = 0\n",
    "\n",
    "        if self.strategy == 'MaxRating':\n",
    "            # query the top 10 highest predicted ratings for each user\n",
    "            \n",
    "            top_items = np.argsort(-estimations)[:topk]    # argsort sorts in increasing order\n",
    "            top_ratings = -np.sort(-estimations)[:topk] # revert to original ratings\n",
    "\n",
    "        elif self.strategy == 'MinRating':\n",
    "            top_items = np.argsort(estimations)[:topk]\n",
    "            top_ratings = np.sort(estimations)[:topk]\n",
    "        \n",
    "        else:\n",
    "            k = int(topk/2)\n",
    "            low_items = np.argsort(estimations)[:topk-k]\n",
    "            low_ratings = np.sort(estimations)[:topk-k]\n",
    "            \n",
    "            high_items = np.argsort(-estimations)[:k]\n",
    "            high_ratings = -np.sort(-estimations)[:k]\n",
    "\n",
    "            top_items = np.concatenate((low_items, high_items))\n",
    "            top_ratings = np.concatenate((low_ratings, high_ratings))\n",
    "        \n",
    "        return (top_items, top_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2262f9",
   "metadata": {},
   "source": [
    "## Get initial training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "628c75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_dic_to_df(rating_dic):\n",
    "    lst = []\n",
    "\n",
    "    for user_iid in range(dataset.user_n): \n",
    "    \n",
    "        if rating_dic[user_iid]:\n",
    "            res = pd.DataFrame(rating_dic[user_iid])\n",
    "            res[2] = user_iid\n",
    "\n",
    "            lst.append(res[[2,0,1]])\n",
    "    \n",
    "\n",
    "    df = pd.concat(lst, ignore_index=True)\n",
    "    df.columns = ['user','item','rating']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59bb95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_n = 5\n",
    "candidate_user_ratings = dataset.list_users_ratings(train_mat)\n",
    "initial_user_ratings = {}\n",
    "\n",
    "for user_iid in range(dataset.user_n):\n",
    "    \n",
    "    initial_user_ratings[user_iid] = []\n",
    "    len_u = len(candidate_user_ratings[user_iid])\n",
    "    \n",
    "    if len_u >= initial_n:\n",
    "        selected_u = list(range(len_u))\n",
    "        random.shuffle(selected_u)\n",
    "        selected_u = selected_u[:initial_n][:]\n",
    "\n",
    "        for ir_idx in selected_u:\n",
    "            ir = candidate_user_ratings[user_iid][ir_idx]\n",
    "            initial_user_ratings[user_iid].append(ir)\n",
    "    \n",
    "    else: # number of ratings less than required initial number\n",
    "        selected_u = list(range(len_u))\n",
    "        random.shuffle(selected_u)\n",
    "        \n",
    "        for ir_idx in selected_u:\n",
    "            ir = candidate_user_ratings[user_iid][ir_idx]\n",
    "            initial_user_ratings[user_iid].append(ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6074dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_train_df = rating_dic_to_df(initial_user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d170f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2755, 3)\n",
      "#users:  (551,)\n",
      "#items:  (553,)\n"
     ]
    }
   ],
   "source": [
    "print(initial_train_df.shape)\n",
    "print('#users: ', np.unique(initial_train_df['user']).shape)\n",
    "print('#items: ', np.unique(initial_train_df['item']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262dfe2",
   "metadata": {},
   "source": [
    "## Learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c38c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_n = 40\n",
    "#mf = NMF(n_components=feature_n, init='random', random_state=2, tol=0.01,\n",
    "#         solver='cd', max_iter=1000, alpha_W=1, alpha_H='same', beta_loss='frobenius',\n",
    "#         l1_ratio=0)\n",
    "mf = NMF(n_components=feature_n, init='random', random_state=0, max_iter=500, verbose=False)\n",
    "learner = PredictionBasedActiveLearner(mf, 'MaxRating', initial_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d571cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for user_iid in range(dataset.user_n):\n",
    "        \n",
    "        # get the items to be queried\n",
    "        query_item_lst = learner.query(user_iid, 10)[0]\n",
    "        candidate_df_u = pd.DataFrame(candidate_user_ratings[user_iid])\n",
    "        query_df = candidate_df_u.loc[candidate_df_u[0].isin(query_item_lst)].copy()\n",
    "        query_df[2] = user_iid\n",
    "        query_df = query_df[[2, 0, 1]]\n",
    "        query_df.columns = [0, 1, 2]\n",
    "        # add to known rating matrix\n",
    "        learner.add_query(query_df)\n",
    "\n",
    "        # remember the items that are unavailable\n",
    "        unavailable_item_lst = [i for i in list(query_item_lst) if i not in list(query_df[1])]\n",
    "        learner.unavl[user_iid] += unavailable_item_lst\n",
    "\n",
    "    learner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15744f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<551x593 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20000 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.known_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8822bd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.known_mat[0,507]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ebb6c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027389769552340557"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.est[0,507]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f96e607b91a2e2d3251db7ddf844b8ed38c6c958a32172526e41c91f117aef26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
